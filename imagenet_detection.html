<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Caffe</title>

    <link rel="stylesheet" href="stylesheets/reset.css">
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-46255508-1', 'daggerfs.com');
    ga('send', 'pageview');
  </script>
    <div class="wrapper">
      <header>
        <h1 class="header"><a href="index.html">Caffe</a></h1>
        <p class="header">Convolutional Architecture for Fast Feature Embedding</p>

        <ul>
          <!--<li class="download"><a class="buttons" href="https://github.com/BVLC/caffe/zipball/master">Download ZIP</a></li>
          <li class="download"><a class="buttons" href="https://github.com/BVLC/caffe/tarball/master">Download TAR</a></li>-->
          <li><a class="buttons github" href="https://github.com/BVLC/caffe">View On GitHub</a></li>
        </ul>
        <p class="header">Maintained by<br><a class="header name" href="http://ucbvlc.org/">BVLC</a></p>
        <p class="header">Created by<br><a class="header name" href="http://daggerfs.com/">Yangqing Jia</a></p>

      </header>
      <section>

      <h1 id="running_windowed_detection_with_caffe">Running Windowed Detection with Caffe</h1>

<p><a href="http://nbviewer.ipython.org/github/BVLC/caffe/blob/gh-pages/selective_search_demo.ipynb">View this page as an IPython Notebook</a> (highly recommended!)</p>
<hr />
<p>This approach follows ideas described in Ross Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik. <em>Rich feature hierarchies for accurate object detection and semantic segmentation</em>. <a href="http://arxiv.org/abs/1311.2524">Arxiv 2013</a>.</p>

<p>First of all, we’ll need a little <a href="https://github.com/sergeyk/selective_search_ijcv_with_python">Python script</a> to run the Matlab Selective Search code.</p>

<p>Let’s run detection on an image of a couple of cats frolicking (one of the ImageNet detection challenge pictures), which we will download from the web. You’ll need a prototxt specifying the network, and a trained model.</p>

<p>We will use <code>examples/imagenet_deploy.prototxt</code> and the <a href="https://www.dropbox.com/s/n3jups0gr7uj0dv/caffe_reference_imagenet_mode
l">caffe_reference_imagene t_model</a>. You’ll need to download the model for yourself, and put it in <code>examples/caffe_reference_imagenet_model</code>.</p>

<pre><code>!mkdir _temp
!curl http://farm1.static.flickr.com/220/512450093_7717fb8ce8.jpg &gt; _temp/cat.jpg
!echo `pwd`/_temp/cat.jpg &gt; _temp/cat.txt
!python ../python/caffe/detection/detector.py --crop_mode=selective_search --pretrained_model=caffe_reference_imagenet_model --model_def=imagenet_deploy.prototxt _temp/cat.txt _temp/cat.h5</code></pre>

<p>Running this outputs a DataFrame with the filenames, selected windows, and their ImageNet scores to an HDF5 file. (We only ran on one image, so the filenames will all be the same.)</p>

<pre><code>import pandas as pd

df = pd.read_hdf(&#39;_temp/cat.h5&#39;, &#39;df&#39;)
print(df.shape)
print(df.iloc[0])

(223, 5)
feat    [6.90396e-06, 1.27811e-06, 1.82159e-06, 1.1020...
ymin                                                    0
xmin                                                    0
ymax                                                  500
xmax                                                  496
Name: /Users/karayev/work/caffe-bvlc/examples/_temp/cat.jpg, dtype: object</code></pre>

<p>In general, <code>detector.py</code> is most efficient when running on a lot of images: it first extracts window proposals for all of them, batches the windows for efficient GPU processing, and then outputs the results. Simply list an image per line in the <code>images_file</code>, and it will process all of them.</p>

<p>Although this guide gives an example of ImageNet detection, <code>detector.py</code> is clever enough to adapt to different Caffe models’ input dimensions, batch size, and output categories. Refer to <code>python detector.py --help</code> and the <code>images_dim</code> and <code>images_mean_file</code> parameters to describe your data set. No need for hardcoding.</p>

<p>Anyway, let’s now load ImageNet class names and make a DataFrame of the features.</p>

<pre><code>with open(&#39;../python/caffe/imagenet/ilsvrc_2012_synset_words.txt&#39;) as f:
    labels_df = pd.DataFrame([
        {
            &#39;synset_id&#39;: l.strip().split(&#39; &#39;)[0],
            &#39;name&#39;: &#39; &#39;.join(l.strip().split(&#39; &#39;)[1:]).split(&#39;,&#39;)[0]
        }
        for l in f.readlines()
    ])
labels_df.sort(&#39;synset_id&#39;)
feats_df = pd.DataFrame(np.vstack(df.feat.values), columns=labels_df[&#39;name&#39;])
print(feats_df.iloc[0])

name
tench                0.000007
goldfish             0.000001
great white shark    0.000002
tiger shark          0.000001
hammerhead           0.000007
electric ray         0.000004
stingray             0.000007
cock                 0.000060
hen                  0.003055
ostrich              0.000010
brambling            0.000004
goldfinch            0.000001
house finch          0.000004
junco                0.000002
indigo bunting       0.000001
...
daisy                    0.000002
yellow lady&#39;s slipper    0.000002
corn                     0.000020
acorn                    0.000011
hip                      0.000003
buckeye                  0.000010
coral fungus             0.000005
agaric                   0.000019
gyromitra                0.000039
stinkhorn                0.000002
earthstar                0.000025
hen-of-the-woods         0.000035
bolete                   0.000037
ear                      0.000008
toilet tissue            0.000019
Name: 0, Length: 1000, dtype: float32</code></pre>

<p>Let’s look at the activations.</p>

<pre><code>gray()
matshow(feats_df.values)
xlabel(&#39;Classes&#39;)
ylabel(&#39;Windows&#39;)




&lt;matplotlib.text.Text at 0x107290150&gt;




&lt;matplotlib.figure.Figure at 0x106877510&gt;</code></pre>

<p><img src="selective_search_demo_files/selective_search_demo_7_2.png" alt="png" /></p>

<p>Now let’s take max across all windows and plot the top classes.</p>

<pre><code>max_s = feats_df.max(0)
max_s.sort(ascending=False)
print(max_s[:10])

name
proboscis monkey       0.923392
tiger cat              0.918685
milk can               0.783663
American black bear    0.637560
broccoli               0.612832
tiger                  0.515798
platypus               0.514660
dhole                  0.509583
lion                   0.496187
dingo                  0.482885
dtype: float32</code></pre>

<p>Okay, there are indeed cats in there (and some nonsense). Picking good localizations is work in progress; manually, we see that the third and thirteenth top detections correspond to the two cats.</p>

<pre><code># Find, print, and display max detection.
window_order = pd.Series(feats_df.values.max(1)).order(ascending=False)

i = window_order.index[3]
j = window_order.index[13]

# Show top predictions for top detection.
f = pd.Series(df[&#39;feat&#39;].iloc[i], index=labels_df[&#39;name&#39;])
print(&#39;Top detection:&#39;)
print(f.order(ascending=False)[:5])
print(&#39;&#39;)

# Show top predictions for 10th top detection.
f = pd.Series(df[&#39;feat&#39;].iloc[j], index=labels_df[&#39;name&#39;])
print(&#39;10th detection:&#39;)
print(f.order(ascending=False)[:5])

# Show top detection in red, 10th top detection in blue.
im = imread(&#39;_temp/cat.jpg&#39;)
imshow(im)
currentAxis = plt.gca()

det = df.iloc[i]
coords = (det[&#39;xmin&#39;], det[&#39;ymin&#39;]), det[&#39;xmax&#39;] - det[&#39;xmin&#39;], det[&#39;ymax&#39;] - det[&#39;ymin&#39;]
currentAxis.add_patch(Rectangle(*coords, fill=False, edgecolor=&#39;r&#39;, linewidth=5))

det = df.iloc[j]
coords = (det[&#39;xmin&#39;], det[&#39;ymin&#39;]), det[&#39;xmax&#39;] - det[&#39;xmin&#39;], det[&#39;ymax&#39;] - det[&#39;ymin&#39;]
currentAxis.add_patch(Rectangle(*coords, fill=False, edgecolor=&#39;b&#39;, linewidth=5))

Top detection:
name
tiger cat       0.882021
tiger           0.075015
tabby           0.024404
lynx            0.012947
Egyptian cat    0.004409
dtype: float32

10th detection:
name
tiger cat           0.681169
Pembroke            0.063924
dingo               0.050501
golden retriever    0.027614
tabby               0.021413
dtype: float32





&lt;matplotlib.patches.Rectangle at 0x108516c90&gt;</code></pre>

<p><img src="selective_search_demo_files/selective_search_demo_11_2.png" alt="png" /></p>

<p>That’s cool. Both of these detections are tiger cats. Let’s take all ‘tiger cat’ detections and NMS them to get rid of overlapping windows.</p>

<pre><code>def nms_detections(dets, overlap=0.5):
    &quot;&quot;&quot;
    Non-maximum suppression: Greedily select high-scoring detections and
    skip detections that are significantly covered by a previously
    selected detection.

    This version is translated from Matlab code by Tomasz Malisiewicz,
    who sped up Pedro Felzenszwalb&#39;s code.

    Parameters</code></pre>
<hr />
<pre><code>    dets: ndarray
        each row is [&#39;xmin&#39;, &#39;ymin&#39;, &#39;xmax&#39;, &#39;ymax&#39;, &#39;score&#39;]
    overlap: float
        minimum overlap ratio (0.5 default)

    Output</code></pre>
<hr />
<pre><code>    dets: ndarray
        remaining after suppression.
    &quot;&quot;&quot;
    if np.shape(dets)[0] &lt; 1:
        return dets

    x1 = dets[:, 0]
    y1 = dets[:, 1]
    x2 = dets[:, 2]
    y2 = dets[:, 3]

    w = x2 - x1
    h = y2 - y1
    area = w * h

    s = dets[:, 4]
    ind = np.argsort(s)

    pick = []
    counter = 0
    while len(ind) &gt; 0:
        last = len(ind) - 1
        i = ind[last]
        pick.append(i)
        counter += 1

        xx1 = np.maximum(x1[i], x1[ind[:last]])
        yy1 = np.maximum(y1[i], y1[ind[:last]])
        xx2 = np.minimum(x2[i], x2[ind[:last]])
        yy2 = np.minimum(y2[i], y2[ind[:last]])

        w = np.maximum(0., xx2 - xx1 + 1)
        h = np.maximum(0., yy2 - yy1 + 1)

        o = w * h / area[ind[:last]]

        to_delete = np.concatenate(
            (np.nonzero(o &gt; overlap)[0], np.array([last])))
        ind = np.delete(ind, to_delete)

    return dets[pick, :]


scores = feats_df[&#39;tiger cat&#39;]
windows = df[[&#39;xmin&#39;, &#39;ymin&#39;, &#39;xmax&#39;, &#39;ymax&#39;]].values
dets = np.hstack((windows, scores[:, np.newaxis]))
nms_dets = nms_detections(dets)</code></pre>

<p>Show top 3 NMS’d detections for ‘tiger cat’ in the image.</p>

<pre><code>imshow(im)
currentAxis = plt.gca()
colors = [&#39;r&#39;, &#39;b&#39;, &#39;y&#39;]
for c, det in zip(colors, nms_dets[:3]):
    currentAxis.add_patch(
        Rectangle((det[0], det[1]), det[2], det[3],
        fill=False, edgecolor=c, linewidth=5)
    )</code></pre>

<p><img src="selective_search_demo_files/selective_search_demo_16_0.png" alt="png" /></p>

<p>Remove the temp directory to clean up.</p>

<pre><code>import shutil
shutil.rmtree(&#39;_temp&#39;)</code></pre>

      </section>
      <footer>
        <p><small>Hosted on <a href="http://pages.github.com">GitHub Pages</a>.</small></p>
      </footer>
    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
  </body>
</html>
