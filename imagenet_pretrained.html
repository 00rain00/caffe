<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Caffe</title>

    <link rel="stylesheet" href="stylesheets/reset.css">
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-46255508-1', 'daggerfs.com');
    ga('send', 'pageview');
  </script>
    <div class="wrapper">
      <header>
        <h1 class="header"><a href="index.html">Caffe</a></h1>
        <p class="header">Convolutional Architecture for Fast Feature Embedding</p>

        <ul>
          <!--<li class="download"><a class="buttons" href="https://github.com/BVLC/caffe/zipball/master">Download ZIP</a></li>
          <li class="download"><a class="buttons" href="https://github.com/BVLC/caffe/tarball/master">Download TAR</a></li>-->
          <li><a class="buttons github" href="https://github.com/BVLC/caffe">View On GitHub</a></li>
        </ul>
        <p class="header">Maintained by<br><a class="header name" href="http://ucbvlc.org/">BVLC</a></p>
        <p class="header">Created by<br><a class="header name" href="http://daggerfs.com/">Yangqing Jia</a></p>

      </header>
      <section>

      <h1 id="running_pretrained_imagenet">Running Pretrained ImageNet</h1>

<p><a href="http://nbviewer.ipython.org/github/BVLC/caffe/blob/master/examples/imagenet_pretrained.ipynb">View this page as an IPython Notebook</a></p>

<p>For easier use of pretrained models, we provide a wrapper specifically written for the case of ImageNet, so one can take an image and directly compute features or predictions from them. Both Python and Matlab wrappers are provided. We will describe the use of the Python wrapper here, and the Matlab wrapper usage is very similar.</p>

<p>We assume that you have successfully compiled Caffe and set the correct <code>PYTHONPATH</code>. If not, please refer to the <a href="installation.html">installation instructions</a>. You will use our pre-trained imagenet model, which you can download (232.57MB) by running <code>models/get_caffe_reference_imagenet_model.sh</code>.Note that this pre-trained model is licensed for academic research / non-commercial use only.</p>

<p>Ready? Let’s start.</p>

<pre><code>from caffe import imagenet
from matplotlib import pyplot

# Set the right path to your model file, pretrained model,
# and the image you would like to classify.
MODEL_FILE = &#39;models/imagenet.prototxt&#39;
PRETRAINED = &#39;models/caffe_reference_imagenet_model&#39;
IMAGE_FILE = &#39;/path/to/lena.png&#39;</code></pre>

<p>Loading a network is easy. imagenet.ImagenetClassifier wraps everything. In default, the classifier will crop the center and corners of an image, as well as their mirrored versions, thus creating a batch of 10 images. If you look at the provided MODEL_FILE you can actually see that we are defining the input batch size to be 10.</p>

<p>If you would like to just do the center, you need to specify center_only=1, and also change the batch size from 10 to 1 in the prototxt.</p>

<pre><code>net = imagenet.ImageNetClassifier(
    MODEL_FILE, PRETRAINED)</code></pre>

<p>We will set the phase to test since we are doing testing, and will first use CPU for the computation.</p>

<pre><code>net.caffenet.set_phase_test()
net.caffenet.set_mode_cpu()</code></pre>

<p>So now, we can do a prediction. Let’s show some output as well:</p>

<pre><code>prediction = net.predict(IMAGE_FILE)
print &#39;prediction shape:&#39;, prediction.shape
pyplot.plot(prediction)

prediction shape: (1000,)
[&lt;matplotlib.lines.Line2D at 0x8faf4d0&gt;]</code></pre>

<p><img src="imagenet_pretrained_files/imagenet_pretrained_7_2.png" alt="png" /></p>

<p>You can see that the prediction is 1000-dimensional, and is pretty sparse. Our pretrained model uses the alphabetical order for the synsets, and if you look at the index that maximizes the prediction score, it is “sombrero”. Reasonable prediction, right?</p>

<p>Now, why don’t we see how long it takes to perform the classification end to end? This result is run from an Intel i5 CPU, so you may observe some performance differences with different machines.</p>

<pre><code>%timeit net.predict(IMAGE_FILE)

1 loops, best of 3: 194 ms per loop</code></pre>

<p>It may look a little slow, but note that it also includes image loading, cropping, and python interfacing time, and the convnet is working on 10 images due to that. As a performance note, if you really want to make prediction fast, you can optionally write things in C and also pipeline the image loading part. But for most applications, the current speed might be fine I guess?</p>

<p>OK, so how about GPU? it is actually pretty easy:</p>

<pre><code>net.caffenet.set_mode_gpu()</code></pre>

<p>Voila! Now we are in GPU mode. Let’s see if the code gives the same result:</p>

<pre><code>prediction = net.predict(IMAGE_FILE)
print &#39;prediction shape:&#39;, prediction.shape
pyplot.plot(prediction)

prediction shape: (1000,)
[&lt;matplotlib.lines.Line2D at 0xee00e90&gt;]</code></pre>

<p><img src="imagenet_pretrained_files/imagenet_pretrained_13_2.png" alt="png" /></p>

<p>Good, everything is the same. And how about time consumption? The following benchmark is obtained on the same machine with a K20 GPU:</p>

<pre><code>%timeit net.predict(IMAGE_FILE)

10 loops, best of 3: 50 ms per loop</code></pre>

<p>Pretty fast right? Not as fast as you expected? Indeed, in this python demo you are seeing only 4 times speedup. But remember - the GPU code is actually very fast, and the data loading, transformation and interfacing actually start to take <strong>more</strong> time than the actual convnet computation itself!</p>

<p>To fully utilize the power of GPUs, you really want to use one of these ideas:</p>

<ul>
<li>Use larger batches, and minimize python call and data transfer overheads.</li>

<li>Pipeline data load operations, like using a subprocess.</li>

<li>Code in C++. A little inconvenient, but maybe worth it if your dataset is really, really large.</li>
</ul>

<h2 id="parting_words">Parting Words</h2>

<p>So this is python! We hope the interface is easy enough for one to use. The python wrapper is interfaced with boost::python, and source code can be found at <code>python/caffe/imagenet</code>. If you would like to achieve some custom functions, you are more than welcome to look at them!</p>

      </section>
      <footer>
        <p><small>Hosted on <a href="http://pages.github.com">GitHub Pages</a>.</small></p>
      </footer>
    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
  </body>
</html>
